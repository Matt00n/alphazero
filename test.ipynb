{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "[1.]\n",
      "(1,)\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "terminated = jnp.logical_or(\n",
    "    1 < 2,\n",
    "    3 < 4,\n",
    ")\n",
    "terminated = jnp.where(\n",
    "    terminated, jnp.ones(1), jnp.zeros(1)\n",
    ").astype(float)\n",
    "truncated = jnp.where(\n",
    "    5 >= 4, 1 - terminated, jnp.zeros_like(terminated)\n",
    ")\n",
    "\n",
    "print(terminated.shape)\n",
    "print(terminated)\n",
    "print(truncated.shape)\n",
    "print(truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.ones(1) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*128*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/module.py:77: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  KeyArray = Union[jax.Array, jax.random.KeyArray]  # pylint: disable=invalid-name\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/recurrent.py:45: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  PRNGKey = jax.random.KeyArray\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/recurrent.py:753: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  init_key: Optional[random.KeyArray] = None,\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/recurrent.py:979: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  init_key: Optional[random.KeyArray] = None,\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/recurrent.py:1003: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  init_key: Optional[random.KeyArray] = None,\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/flax/linen/stochastic.py:28: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys.\n",
      "  KeyArray = Union[jax.Array, jax.random.KeyArray]\n",
      "/Users/matthiaslehmann/miniforge3/envs/rl_algo/lib/python3.11/site-packages/tensorflow/python/framework/dtypes.py:35: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
      "  from tensorflow.tsl.python.lib.core import pywrap_ml_dtypes\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from envs import make_env, Transition, MCTSTransition, has_discrete_action_space, is_atari_env\n",
    "# from envs.brax_v1_wrappers import wrap_for_training\n",
    "from envs.brax_wrappers import EvalWrapper, wrap_for_training\n",
    "from networks.policy import Policy, ForwardPass\n",
    "from networks.networks import FeedForwardNetwork, ActivationFn, make_policy_network, make_value_network, make_atari_feature_extractor\n",
    "from networks.distributions import NormalTanhDistribution, ParametricDistribution, PolicyNormalDistribution, DiscreteDistribution\n",
    "import replay_buffers\n",
    "import running_statistics\n",
    "from gymnax import gymnax\n",
    "from gymnax.gymnax.wrappers.brax import GymnaxToBraxWrapper, State\n",
    "import mctx\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "is_atari = is_atari_env('CartPole-v1')\n",
    "environment, env_params = gymnax.make('CartPole-v1')\n",
    "discrete_action_space = has_discrete_action_space(environment, env_params)\n",
    "if not discrete_action_space:\n",
    "    raise NotImplementedError('Currently only discrete action spaces are supported.')\n",
    "environment = GymnaxToBraxWrapper(environment)\n",
    "\n",
    "env = wrap_for_training(\n",
    "    environment,\n",
    "    episode_length=500,\n",
    "    action_repeat=1,\n",
    ")\n",
    "key = jax.random.PRNGKey(42)\n",
    "key_envs, key = jax.random.split(key, 2)\n",
    "reset_fn = jax.jit(jax.vmap(env.reset))\n",
    "key_envs = jax.random.split(key_envs, 8 // 1)\n",
    "key_envs = jnp.reshape(key_envs,\n",
    "                        (1, -1) + key_envs.shape[1:])\n",
    "env_state = reset_fn(key_envs)\n",
    "\n",
    "action_size = env.action_size()\n",
    "\n",
    "if is_atari:\n",
    "    observation_shape = env_state.obs.shape[-3:]\n",
    "else:\n",
    "    observation_shape = env_state.obs.shape[-1:]\n",
    "\n",
    "dummy_obs = jnp.zeros(observation_shape,)\n",
    "dummy_action = jnp.zeros((action_size,))\n",
    "dummy_transition = MCTSTransition(  # pytype: disable=wrong-arg-types  # jax-ndarray\n",
    "    observation=dummy_obs,\n",
    "    action=dummy_action,\n",
    "    reward=0.,\n",
    "    discount=0.,\n",
    "    next_observation=dummy_obs,\n",
    "    target_policy_probs=jnp.zeros((action_size,)),\n",
    "    target_value=0.,\n",
    "    extras={\n",
    "        'state_extras': {\n",
    "            'truncation': 0.\n",
    "        },\n",
    "        'policy_extras': {\n",
    "            'prior_log_prob': dummy_action,\n",
    "            'raw_action': dummy_action\n",
    "        }\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTSTransition(observation=Array([0., 0., 0., 0.], dtype=float32), action=Array([0., 0.], dtype=float32), reward=0.0, discount=0.0, next_observation=Array([0., 0., 0., 0.], dtype=float32), target_policy_probs=Array([0., 0.], dtype=float32), target_value=0.0, extras={'state_extras': {'truncation': 0.0}, 'policy_extras': {'prior_log_prob': Array([0., 0.], dtype=float32), 'raw_action': Array([0., 0.], dtype=float32)}})\n",
      "(20,)\n",
      "MCTSTransition(observation=Array([0., 0., 0., 0.], dtype=float32), action=Array([0., 0.], dtype=float32), reward=Array(0., dtype=float32), discount=Array(0., dtype=float32), next_observation=Array([0., 0., 0., 0.], dtype=float32), target_policy_probs=Array([0., 0.], dtype=float32), target_value=Array(0., dtype=float32), extras={'policy_extras': {'prior_log_prob': Array([0., 0.], dtype=float32), 'raw_action': Array([0., 0.], dtype=float32)}, 'state_extras': {'truncation': Array(0., dtype=float32)}})\n"
     ]
    }
   ],
   "source": [
    "dummy_flatten, _unflatten_fn = jax.flatten_util.ravel_pytree(\n",
    "        dummy_transition\n",
    "    )\n",
    "\n",
    "print(dummy_transition)\n",
    "print(dummy_flatten.shape)\n",
    "print(_unflatten_fn(dummy_flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, logits_rng, search_rng = jax.random.split(key, 3)\n",
    "\n",
    "# logits at root produced by the prior policy \n",
    "def forward()\n",
    "prior_logits, value = forward(env_state.obs)\n",
    "\n",
    "use_mixed_value = False\n",
    "\n",
    "# NOTE: For AlphaZero embedding is env_state, for MuZero\n",
    "# the root output would be the output of MuZero representation network.\n",
    "root = mctx.RootFnOutput(\n",
    "    prior_logits=prior_logits,\n",
    "    value=value,\n",
    "    # The embedding is used only to implement the MuZero model.\n",
    "    embedding=env_state, \n",
    ")\n",
    "\n",
    "# The recurrent_fn is provided by MuZero dynamics network.\n",
    "# Or true environment for AlphaZero\n",
    "# TODO MCTS: pass in dynamics function for MuZero\n",
    "def recurrent_fn(params, rng_key, action, embedding):\n",
    "    # environment (model)\n",
    "    env_state = embedding\n",
    "    nstate = env.step(env_state, action)\n",
    "\n",
    "    # policy & value networks\n",
    "    prior_logits, value = forward(env_state.obs)\n",
    "\n",
    "    # Create the new MCTS node.\n",
    "    recurrent_fn_output = mctx.RecurrentFnOutput(\n",
    "        reward=nstate.reward,\n",
    "        # discount when terminal state reached\n",
    "        discount=1 - nstate.done,\n",
    "        # prior for the new state\n",
    "        prior_logits=prior_logits,\n",
    "        # value for the new state\n",
    "        value=value,\n",
    "    )\n",
    "\n",
    "    # Return the new node and the new environment.\n",
    "    return recurrent_fn_output, nstate\n",
    "\n",
    "# Running the search.\n",
    "policy_output = mctx.gumbel_muzero_policy(\n",
    "    params=(),\n",
    "    rng_key=search_rng,\n",
    "    root=root,\n",
    "    recurrent_fn=recurrent_fn,\n",
    "    num_simulations=30,\n",
    "    max_num_considered_actions=16,\n",
    "    qtransform=partial(\n",
    "        mctx.qtransform_completed_by_mix_value,\n",
    "        use_mixed_value=use_mixed_value),\n",
    ")\n",
    "\n",
    "actions = policy_output.action\n",
    "action_weights = policy_output.action_weights\n",
    "best_actions = jnp.argmax(action_weights, axis=-1).astype(jnp.int32)\n",
    "actions = jax.lax.select(deterministic_actions, best_actions, actions)\n",
    "\n",
    "search_value = policy_output.search_tree.summary().value\n",
    "\n",
    "policy_extras = {\n",
    "    'prior_log_prob': tfd.Categorical(logits=prior_logits).log_prob(actions),\n",
    "    'raw_action': actions\n",
    "}\n",
    "\n",
    "nstate = env.step(env_state, actions)\n",
    "state_extras = {x: nstate.info[x] for x in extra_fields}\n",
    "return nstate, MCTSTransition(  # pytype: disable=wrong-arg-types  # jax-ndarray\n",
    "    observation=env_state.obs,\n",
    "    action=actions,\n",
    "    reward=nstate.reward,\n",
    "    discount=1 - nstate.done,\n",
    "    next_observation=nstate.obs,\n",
    "    target_policy_probs=action_weights,\n",
    "    target_value=search_value,\n",
    "    extras={\n",
    "        'policy_extras': policy_extras, \n",
    "        'state_extras': state_extras\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chex\n",
    "\n",
    "def n_step_bootstrapped_targets(\n",
    "        rewards: jnp.ndarray,\n",
    "        discounts: jnp.ndarray,\n",
    "        termination_discount: jnp.ndarray,\n",
    "        observations: jnp.ndarray,\n",
    "        values: jnp.ndarray,\n",
    "        n: int = 5,\n",
    "        gamma: float = 1.,\n",
    "    ) -> jnp.ndarray:\n",
    "    \"\"\"Computes n-step bootstrapped return targets over a sequence.\n",
    "\n",
    "    Args:\n",
    "        rewards: rewards at times [1, ..., T].\n",
    "        discounts: discounts at times [1, ..., T].\n",
    "        termination_discount: discount from termination at times [1, ..., T].\n",
    "        observations: observation at time [1, ...., T].\n",
    "        values: values at time [1, ...., T].\n",
    "        n: number of steps over which to accumulate reward before bootstrapping.\n",
    "\n",
    "    Returns:\n",
    "        estimated bootstrapped returns prefixes at times [0, ...., T-1]\n",
    "        observation to bootstrap from at times [0, ...., T-1]\n",
    "        discount factor for bootstrap value at times [0, ...., T-1]\n",
    "    \"\"\"\n",
    "    chex.assert_type([rewards, discounts, values], float)\n",
    "    chex.assert_equal_shape([rewards, discounts, values])\n",
    "    batch_shape = rewards.shape\n",
    "    seq_len = batch_shape[0]\n",
    "\n",
    "    # Shift bootstrap values by n and pad end of sequence with last value v_t[-1].\n",
    "    pad_size = min(n - 1, seq_len)\n",
    "    bootstrap_observations = jnp.concatenate([observations[n - 1:], jnp.array([observations[-1]] * pad_size)])\n",
    "    bootstrap_values = jnp.concatenate([values[n - 1:], jnp.array([values[-1]] * pad_size)])\n",
    "\n",
    "    # Pad sequences. Shape is now (T + n - 1, ...).\n",
    "    rewards = jnp.concatenate([rewards, jnp.zeros((n - 1,) + batch_shape[1:])])\n",
    "    discounts = jnp.concatenate([discounts, jnp.ones((n - 1,) + batch_shape[1:])]) * gamma\n",
    "\n",
    "    value_prefix_targets = jax.lax.dynamic_slice_in_dim(rewards, n-1, seq_len)\n",
    "    bootstrap_discounts = jnp.concatenate([termination_discount, jnp.ones((n - 1,) + batch_shape[1:])]) * gamma\n",
    "    bootstrap_discounts = jax.lax.dynamic_slice_in_dim(bootstrap_discounts, n-1, seq_len)\n",
    "\n",
    "    def f(carry, unused_t):\n",
    "        i, value_prefix_targets, bootstrap_discounts = carry\n",
    "        i -= 1\n",
    "        r_ = jax.lax.dynamic_slice_in_dim(rewards, i, seq_len)\n",
    "        discount_ = jax.lax.dynamic_slice_in_dim(discounts, i, seq_len)\n",
    "        value_prefix_targets = r_ + discount_ * value_prefix_targets\n",
    "        bootstrap_discounts *= discount_\n",
    "        return (i, value_prefix_targets, bootstrap_discounts), unused_t\n",
    "\n",
    "    (_, value_prefix_targets, bootstrap_discounts), _ = jax.lax.scan(\n",
    "        f, (n-1, value_prefix_targets, bootstrap_discounts),\n",
    "        (),\n",
    "        length=n-1)\n",
    "\n",
    "    return value_prefix_targets, bootstrap_observations, bootstrap_values, bootstrap_discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 5.125 ,  7.375 ,  7.4375,  8.875 ,  9.75  ,  9.5   ,  7.    ,\n",
       "       18.125 , 17.125 , 13.125 ], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_bootstrapped_returns(\n",
    "        rewards=jnp.array([1,2,3,4,5,6,7,8,9,10], dtype=float),\n",
    "        discount_t=jnp.array([1,1,1,1,1,1,0,1,1,1], dtype=float),\n",
    "        v_t=jnp.array([10,20,30,40,50,60,70,80,90,100], dtype=float),\n",
    "        n=5,\n",
    "        discount=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5625  5.5     7.4375  8.875   9.75    9.5     7.     15.     14.\n",
      " 10.    ]\n",
      "[ 50.  60.  70.  80.  90. 100. 100. 100. 100. 100.]\n",
      "[ 50.  60.  70.  80.  90. 100. 100. 100. 100. 100.]\n",
      "[0.03125 0.03125 0.      0.      0.      0.      0.      0.03125 0.03125\n",
      " 0.03125]\n",
      "[ 5.125   7.375   7.4375  8.875   9.75    9.5     7.     18.125  17.125\n",
      " 13.125 ]\n"
     ]
    }
   ],
   "source": [
    "value_prefix_targets, bootstrap_observations, bootstrap_values, bootstrap_discounts = n_step_bootstrapped_targets(\n",
    "        rewards=jnp.array([1,2,3,4,5,6,7,8,9,10], dtype=float),\n",
    "        discounts=jnp.array([1,1,1,1,1,1,0,1,1,1], dtype=float),\n",
    "        termination_discount=jnp.array([1,1,1,1,1,1,0,1,1,1], dtype=float),\n",
    "        observations=jnp.array([10,20,30,40,50,60,70,80,90,100], dtype=float),\n",
    "        values=jnp.array([10,20,30,40,50,60,70,80,90,100], dtype=float),\n",
    "        n=5,\n",
    "        gamma=0.5,\n",
    "    )\n",
    "\n",
    "print(value_prefix_targets)\n",
    "print(bootstrap_observations)\n",
    "print(bootstrap_values)\n",
    "print(bootstrap_discounts)\n",
    "print(bootstrap_discounts*bootstrap_observations + value_prefix_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5625"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1 + 3*0.25 + 4*0.125 + 5*0.125*0.5 # + 50*0.125*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  230.,  6320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  330.,  7320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  430.,  8320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  530.,  9320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  630., 11320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  730., 12320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  730., 12320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  730., 12320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  730., 12320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.],\n",
       "       [  730., 12320.,    30.,    40.,    50.,    60.,    70.,    80.,\n",
       "           90.,   100.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_t=jnp.array([[10,120,30,40,50,60,70,80,90,100],\n",
    "               [20,220,30,40,50,60,70,80,90,100],\n",
    "               [30,320,30,40,50,60,70,80,90,100],\n",
    "               [130,4320,30,40,50,60,70,80,90,100],\n",
    "               [230,6320,30,40,50,60,70,80,90,100],\n",
    "               [330,7320,30,40,50,60,70,80,90,100],\n",
    "               [430,8320,30,40,50,60,70,80,90,100],\n",
    "               [530,9320,30,40,50,60,70,80,90,100],\n",
    "               [630,11320,30,40,50,60,70,80,90,100],\n",
    "               [730,12320,30,40,50,60,70,80,90,100],], dtype=float)\n",
    "jnp.concatenate([v_t[5 - 1:], jnp.array([v_t[-1]] * 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.000e+01, 1.200e+02, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [2.000e+01, 2.200e+02, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [3.000e+01, 3.200e+02, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [1.300e+02, 4.320e+03, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [2.300e+02, 6.320e+03, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [3.300e+02, 7.320e+03, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [4.300e+02, 8.320e+03, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [5.300e+02, 9.320e+03, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [6.300e+02, 1.132e+04, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [7.300e+02, 1.232e+04, 3.000e+01, 4.000e+01, 5.000e+01, 6.000e+01,\n",
       "        7.000e+01, 8.000e+01, 9.000e+01, 1.000e+02],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards=jnp.array([[10,120,30,40,50,60,70,80,90,100],\n",
    "               [20,220,30,40,50,60,70,80,90,100],\n",
    "               [30,320,30,40,50,60,70,80,90,100],\n",
    "               [130,4320,30,40,50,60,70,80,90,100],\n",
    "               [230,6320,30,40,50,60,70,80,90,100],\n",
    "               [330,7320,30,40,50,60,70,80,90,100],\n",
    "               [430,8320,30,40,50,60,70,80,90,100],\n",
    "               [530,9320,30,40,50,60,70,80,90,100],\n",
    "               [630,11320,30,40,50,60,70,80,90,100],\n",
    "               [730,12320,30,40,50,60,70,80,90,100],], dtype=float)\n",
    "batch_shape = rewards.shape\n",
    "jnp.concatenate([rewards, jnp.zeros((5 - 1,) + batch_shape[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.zeros((5 - 1,) + batch_shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1 + 3*0.25 + 4*0.125 + 5*0.125*0.5 + 50*0.125*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "\n",
    "class MCTSTransition(NamedTuple):\n",
    "    \"\"\"Container for a transition.\"\"\"\n",
    "    observation: jnp.array\n",
    "    action: jnp.array\n",
    "    reward: jnp.array\n",
    "\n",
    "data = MCTSTransition(observation=jnp.zeros((4,10,3)), action=jnp.zeros((4,10)), reward=jnp.zeros((4,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTSTransition(observation=Array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32), action=Array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32), reward=Array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._replace(action=jnp.ones((4,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = jnp.array([[1,2,3,4], [5,6,7,8]])\n",
    "chosen_action_logits = jnp.array([[11,22,33,44], [55,66,77,88]])\n",
    "kappa = 0.5\n",
    "num_atoms = 4\n",
    "\n",
    "# target = jnp.array([[1], [5]])\n",
    "# chosen_action_logits = jnp.array([[3], [9]])\n",
    "# kappa = 100000\n",
    "# num_atoms = 1\n",
    "\n",
    "# bellman_errors = (target[:, None, :] -\n",
    "#                       chosen_action_logits[:, :, None])  # Input `u' of Eq. 9.\n",
    "bellman_errors = (jnp.expand_dims(target, -2) -\n",
    "                      jnp.expand_dims(chosen_action_logits, -1))\n",
    "# Eq. 9 of paper.\n",
    "huber_loss = (\n",
    "    (jnp.abs(bellman_errors) <= kappa).astype(jnp.float32) *\n",
    "    0.5 * bellman_errors ** 2 +\n",
    "    (jnp.abs(bellman_errors) > kappa).astype(jnp.float32) *\n",
    "    kappa * (jnp.abs(bellman_errors) - 0.5 * kappa))\n",
    "\n",
    "tau_hat = ((jnp.arange(num_atoms, dtype=jnp.float32) + 0.5) /\n",
    "            num_atoms)  # Quantile midpoints.  See Lemma 2 of paper.\n",
    "# Eq. 10 of paper.\n",
    "tau_bellman_diff = jnp.abs(\n",
    "    tau_hat[None, :, None] - (bellman_errors < 0).astype(jnp.float32))\n",
    "quantile_huber_loss = tau_bellman_diff * huber_loss\n",
    "# Sum over tau dimension, average over target value dimension.\n",
    "loss = jnp.sum(jnp.mean(quantile_huber_loss, 2), 1)\n",
    "final_loss = jnp.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(37.875, dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(5., dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(0.5 * (target - chosen_action_logits)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1., 4.], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.array([[1,2,3],[4,4,5]]), -1)\n",
    "jnp.mean(jnp.array([[1],[4]]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000,)\n",
      "8.988299 8.988299\n",
      "9.0 9.0\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "\n",
    "sample_key = jax.random.PRNGKey(103)\n",
    "x_sample_key = jax.random.PRNGKey(13)\n",
    "sample_batch_size = 10000\n",
    "sample_position = 4\n",
    "insert_position = 15\n",
    "\n",
    "idx = jax.random.randint(\n",
    "            sample_key,\n",
    "            (sample_batch_size,),\n",
    "            minval=sample_position,\n",
    "            maxval=insert_position,\n",
    "        )\n",
    "c_idx = jax.random.choice(\n",
    "    sample_key,\n",
    "    jnp.arange(sample_position, insert_position),\n",
    "    (sample_batch_size,),\n",
    "    replace=True,\n",
    "    p=None,\n",
    ")\n",
    "\n",
    "print(idx.shape, c_idx.shape)\n",
    "print(jnp.mean(idx), jnp.mean(c_idx))\n",
    "print(jnp.median(idx), jnp.median(c_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 9]\n",
      "[-1 -2 -3]\n",
      "[[ 1  2 -1]\n",
      " [ 4  5 -2]\n",
      " [ 7  8 -3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = jnp.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(data[:, -1])\n",
    "\n",
    "data = data.at[:, -1].set(jnp.array([-1,-2,-3]))\n",
    "print(data[:, -1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 1., 1., 1., 1., 1., 1., 2.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "test = jnp.ones((6,8))\n",
    "\n",
    "idx = jnp.array([0,0,0,0])\n",
    "new_val = jnp.ones((4,)) * 2\n",
    "\n",
    "test = test.at[idx, -1].set(new_val)\n",
    "\n",
    "# batch = jnp.take(buffer_state.data, idx, axis=0, mode='wrap')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.expand_dims(jnp.ones(4), (0, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[3. 2. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = jnp.zeros(4)\n",
    "\n",
    "c = a.at[jnp.array([0,1,0,2,0,1])].add(1)\n",
    "\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "\n",
    "sample_dist_logits = jnp.array([[1,2,3,4], [3,3,-50,1], [1,1,1,1]], dtype=float)\n",
    "empirical_logits = jnp.zeros_like(sample_dist_logits)\n",
    "\n",
    "sample_dist_logits = jnp.expand_dims(sample_dist_logits, axis=1)\n",
    "batch_size = empirical_logits.shape[0]\n",
    "samples = jax.random.categorical(jax.random.PRNGKey(14), sample_dist_logits, shape=(batch_size, num_samples))\n",
    "\n",
    "# empirical_logits = empirical_logits.at[jnp.arange(batch_size), samples].add(1.)\n",
    "# empirical_logits = empirical_logits.at[samples].add(1.)\n",
    "# empirical_logits = empirical_logits.at[batch_size, samples].add(1.)\n",
    "\n",
    "def update(x, *indices):\n",
    "  return x.at[indices].add(1.)\n",
    "\n",
    "batch_update = jax.vmap(update)\n",
    "empirical_logits = batch_update(empirical_logits, samples) / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0343 0.0847 0.2402 0.6408]\n",
      " [0.465  0.4692 0.     0.0658]\n",
      " [0.2522 0.2484 0.2537 0.2457]]\n",
      "[[[3.2058604e-02 8.7144323e-02 2.3688284e-01 6.4391428e-01]]\n",
      "\n",
      " [[4.6831053e-01 4.6831053e-01 4.4970365e-24 6.3378938e-02]]\n",
      "\n",
      " [[2.5000000e-01 2.5000000e-01 2.5000000e-01 2.5000000e-01]]]\n"
     ]
    }
   ],
   "source": [
    "print(empirical_logits)\n",
    "print(jax.nn.softmax(sample_dist_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9.3571980e-14 2.0610600e-09 4.5397868e-05 9.9995458e-01]]\n",
      "\n",
      " [[5.0000000e-01 5.0000000e-01 0.0000000e+00 1.0305768e-09]]\n",
      "\n",
      " [[2.5000000e-01 2.5000000e-01 2.5000000e-01 2.5000000e-01]]]\n",
      "[[[9.3571980e-14 2.0610600e-09 4.5397868e-05 9.9995458e-01]]\n",
      "\n",
      " [[5.0000000e-01 5.0000000e-01 0.0000000e+00 1.0305768e-09]]\n",
      "\n",
      " [[2.5000000e-01 2.5000000e-01 2.5000000e-01 2.5000000e-01]]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def _apply_temperature(logits, temperature):\n",
    "  \"\"\"Returns `logits / temperature`, supporting also temperature=0.\"\"\"\n",
    "  # The max subtraction prevents +inf after dividing by a small temperature.\n",
    "  logits = logits - jnp.max(logits, keepdims=True, axis=-1)\n",
    "  tiny = jnp.finfo(logits.dtype).tiny\n",
    "  return logits / jnp.maximum(tiny, temperature)\n",
    "\n",
    "temp = 0.1\n",
    "print(jax.nn.softmax(sample_dist_logits / temp))\n",
    "print(jax.nn.softmax(_apply_temperature(sample_dist_logits, temp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
